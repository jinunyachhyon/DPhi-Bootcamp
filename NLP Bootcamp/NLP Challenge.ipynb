{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4807970c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train = pd.read_csv(\"Train_Data.csv\") #read train csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "462e1f41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>is_sarcastic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>supreme court votes 7-2 to legalize all worldl...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hungover man horrified to learn he made dozens...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>emily's list founder: women are the 'problem s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>send your kids back to school with confidence</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>watch: experts talk pesticides and health</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44257</th>\n",
       "      <td>greece seeks to reassure europe as tensions rise</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44258</th>\n",
       "      <td>vatican says transgender man cannot become a g...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44259</th>\n",
       "      <td>protesters ejected from donald trump rally aft...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44260</th>\n",
       "      <td>italian recipes that are oldies but goodies</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44261</th>\n",
       "      <td>area loser blissfully unaffected by whims of s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>44262 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                headline  is_sarcastic\n",
       "0      supreme court votes 7-2 to legalize all worldl...             1\n",
       "1      hungover man horrified to learn he made dozens...             1\n",
       "2      emily's list founder: women are the 'problem s...             0\n",
       "3          send your kids back to school with confidence             0\n",
       "4              watch: experts talk pesticides and health             0\n",
       "...                                                  ...           ...\n",
       "44257   greece seeks to reassure europe as tensions rise             0\n",
       "44258  vatican says transgender man cannot become a g...             0\n",
       "44259  protesters ejected from donald trump rally aft...             0\n",
       "44260        italian recipes that are oldies but goodies             0\n",
       "44261  area loser blissfully unaffected by whims of s...             1\n",
       "\n",
       "[44262 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b2d037d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 44262 entries, 0 to 44261\n",
      "Data columns (total 2 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   headline      44262 non-null  object\n",
      " 1   is_sarcastic  44262 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 691.7+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4c67958",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().values.any() #check any null value or not in train csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb02157c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hungover man horrified to learn he made dozens of plans last night'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['headline'].iloc[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b833cbf",
   "metadata": {},
   "source": [
    "# Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "477076a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['headline']= train['headline'].str.replace(\"\\r\", \" \") #replacing \\r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0dde556f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['headline']= train['headline'].str.replace(\"\\n\", \" \") #replacing \\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e6e1892",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['headline']= train['headline'].str.replace(\"    \", \" \")  #replacing double spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8553f00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['headline']= train['headline'].str.replace('\"', '') #replacing ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67228be7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hungover man horrified to learn he made dozens of plans last night'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['headline'].iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb6eb3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['headline']= train['headline'].str.lower() #lowering casing the text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f7e79ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nyach\\AppData\\Local\\Temp\\ipykernel_10256\\800866778.py:6: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  train['headline'] = train['headline'].str.replace(i, '')\n"
     ]
    }
   ],
   "source": [
    "#cleaning punctuation signs \n",
    "punctuation_signs = list(\"?:!.,;\")\n",
    "train['headline'] = train['headline']\n",
    "\n",
    "for i in punctuation_signs:\n",
    "    train['headline'] = train['headline'].str.replace(i, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1e063e8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'supreme court votes 7-2 to legalize all worldly vices'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['headline'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e9f47b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning possessive pronouns\n",
    "train['headline'] = train['headline'].str.replace(\"'s\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7a0037a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\nyach\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Downloading the stop words list\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4fc0c60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Loading the stop words in english\n",
    "stop_words = list(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8dad416c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2c3c1027",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nyach\\AppData\\Local\\Temp\\ipykernel_10256\\3243000753.py:4: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  train['headline'] = train['headline'].str.replace(stopword, '')\n"
     ]
    }
   ],
   "source": [
    "#removing stop words\n",
    "for i in stop_words:\n",
    "    stopword = r\"\\b\" + i + r\"\\b\"\n",
    "    train['headline'] = train['headline'].str.replace(stopword, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "be17d476",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'supreme court votes 7-2  legalize  worldly vices'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['headline'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c81f607c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hungover man horrified  learn  made dozens  plans last night'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['headline'].iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "df5257e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>is_sarcastic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>supreme court votes 7-2  legalize  worldly vices</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hungover man horrified  learn  made dozens  pl...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>emily list founder women   'problem solvers'  ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>send  kids back  school  confidence</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>watch experts talk pesticides  health</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44257</th>\n",
       "      <td>greece seeks  reassure europe  tensions rise</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44258</th>\n",
       "      <td>vatican says transgender man cannot become  go...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44259</th>\n",
       "      <td>protesters ejected  donald trump rally  holdin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44260</th>\n",
       "      <td>italian recipes   oldies  goodies</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44261</th>\n",
       "      <td>area loser blissfully unaffected  whims  stock...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>44262 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                headline  is_sarcastic\n",
       "0       supreme court votes 7-2  legalize  worldly vices             1\n",
       "1      hungover man horrified  learn  made dozens  pl...             1\n",
       "2      emily list founder women   'problem solvers'  ...             0\n",
       "3                    send  kids back  school  confidence             0\n",
       "4                  watch experts talk pesticides  health             0\n",
       "...                                                  ...           ...\n",
       "44257       greece seeks  reassure europe  tensions rise             0\n",
       "44258  vatican says transgender man cannot become  go...             0\n",
       "44259  protesters ejected  donald trump rally  holdin...             0\n",
       "44260                  italian recipes   oldies  goodies             0\n",
       "44261  area loser blissfully unaffected  whims  stock...             1\n",
       "\n",
       "[44262 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#after text preprocessing\n",
    "train "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d27a27",
   "metadata": {},
   "source": [
    "# Split Train_data.csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "380c6198",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(train['headline'],train['is_sarcastic'],\n",
    "                                                    test_size=0.3, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b1beca5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10080    van jones tough-guy 'trumpzilla'  become 'pres...\n",
       "32437    usâ€“cuba relations end  obama hit  foul ball  e...\n",
       "34418                     7 phrases   never say   argument\n",
       "8688              teen anxious  cigarette addiction  kick \n",
       "17114    god irritated guests   understand  time  leave...\n",
       "                               ...                        \n",
       "6265      consumer financial protection bureau  governm...\n",
       "11284                    never  -male panels ubs exec says\n",
       "38158    ' sleep  target chic new modern home collectio...\n",
       "860        6 incredible photos  show  world  need  protect\n",
       "15795     seeing  fifth-grader get bullied  group  boys...\n",
       "Name: headline, Length: 30983, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3cd863a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12782                       north dakota  heard   48 hours\n",
       "42915    report  going  take way    inconceivable act  ...\n",
       "33043    states' rights rancher ryan bundy  run  nevada...\n",
       "1121     watching thousands march   honor unlocks deepe...\n",
       "38782           debate  two   unthinkable  united  country\n",
       "                               ...                        \n",
       "29585    google combats holocaust-denying search result...\n",
       "10714    chrissy teigen hot take  ice cream trends coul...\n",
       "41705                fell  love carrying another man child\n",
       "31786    mom hilarious story   morning shows  hectic li...\n",
       "3382     report underpaid migrant laborers working 18 h...\n",
       "Name: headline, Length: 13279, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2b4dbc2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10080    0\n",
       "32437    1\n",
       "34418    0\n",
       "8688     1\n",
       "17114    1\n",
       "        ..\n",
       "6265     0\n",
       "11284    0\n",
       "38158    0\n",
       "860      0\n",
       "15795    0\n",
       "Name: is_sarcastic, Length: 30983, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d93eea83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12782    1\n",
       "42915    1\n",
       "33043    0\n",
       "1121     1\n",
       "38782    0\n",
       "        ..\n",
       "29585    0\n",
       "10714    0\n",
       "41705    0\n",
       "31786    0\n",
       "3382     1\n",
       "Name: is_sarcastic, Length: 13279, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "08f78e5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((30983,), (13279,), (30983,), (13279,))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape,X_test.shape,y_train.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713b4e81",
   "metadata": {},
   "source": [
    "# Extract TF-IDF Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d8355b62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30983, 15000)\n",
      "(13279, 15000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#parameter\n",
    "ngram_range = (1,2) #both unigrams and bigrams \n",
    "min_df = 1\n",
    "max_df = 100\n",
    "max_features = 15000\n",
    "tfidf = TfidfVectorizer(encoding='utf-8',\n",
    "                        ngram_range=ngram_range,\n",
    "                        stop_words=None,\n",
    "                        lowercase=False,\n",
    "                        max_df=max_df,\n",
    "                        min_df=min_df,\n",
    "                        max_features=max_features,\n",
    "                        norm='l2',\n",
    "                        sublinear_tf=True)\n",
    "                        \n",
    "features_train = tfidf.fit_transform(X_train).toarray()\n",
    "labels_train = y_train\n",
    "print(features_train.shape)\n",
    "\n",
    "features_test = tfidf.transform(X_test).toarray()\n",
    "labels_test = y_test\n",
    "print(features_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ffde3b",
   "metadata": {},
   "source": [
    "# Using various sklearn models to compare accuracy among them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "49d52276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.8467505083214097\n"
     ]
    }
   ],
   "source": [
    "##naive bias\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "\n",
    "nb = Pipeline([('vect', CountVectorizer()),\n",
    "               ('tfidf', TfidfTransformer()),\n",
    "               ('clf', MultinomialNB()),\n",
    "              ])\n",
    "modelnb = nb.fit(X_train, y_train)\n",
    "\n",
    "y_pred = nb.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b78ea12b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.8990134799307177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\nyach\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "logreg = Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', LogisticRegression(n_jobs=1, C=1e5)),\n",
    "               ])\n",
    "model_logreg = logreg.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a5bdef20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.6168386173657655\n"
     ]
    }
   ],
   "source": [
    "#linear svm\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd = Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42, max_iter=5, tol=None)),\n",
    "               ])\n",
    "model_svm= sgd.fit(X_train, y_train)\n",
    "\n",
    "y_pred = sgd.predict(X_test)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6ff7ffa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is : 0.6747496046389035\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "lr = Pipeline([('tfidf',TfidfVectorizer()),\n",
    "               ('gbc',GradientBoostingClassifier())])\n",
    "model_lr=lr.fit(X_train,y_train)\n",
    "y_pred1 = lr.predict(X_test)\n",
    "\n",
    "print(f\"Accuracy is : {accuracy_score(y_pred1,y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1780a17d",
   "metadata": {},
   "source": [
    "Since from sklearn.linear_model, LogisticRegression has the maximum accuracy with 0.8990134799307177, using LogisticRegression to predict for Test_Data.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7b1e10",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "22c7f54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test=pd.read_csv(\"Test_Data.csv\") #reading test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d5119d92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>area stand-up comedian questions the deal with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dozens of glowing exit signs mercilessly taunt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>perfect response to heckler somewhere in prop ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gop prays for ossoff lossoff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>trevor noah says the scary truth about trump's...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11061</th>\n",
       "      <td>house conservatives claim democrats have faile...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11062</th>\n",
       "      <td>area man having one of his little bursts of en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11063</th>\n",
       "      <td>there is nothing libertarian about conservatives</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11064</th>\n",
       "      <td>mike pompeo startled after seeing 'beware of h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11065</th>\n",
       "      <td>how pets can help prevent suicide #nspw2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11066 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                headline\n",
       "0      area stand-up comedian questions the deal with...\n",
       "1      dozens of glowing exit signs mercilessly taunt...\n",
       "2      perfect response to heckler somewhere in prop ...\n",
       "3                           gop prays for ossoff lossoff\n",
       "4      trevor noah says the scary truth about trump's...\n",
       "...                                                  ...\n",
       "11061  house conservatives claim democrats have faile...\n",
       "11062  area man having one of his little bursts of en...\n",
       "11063   there is nothing libertarian about conservatives\n",
       "11064  mike pompeo startled after seeing 'beware of h...\n",
       "11065        how pets can help prevent suicide #nspw2017\n",
       "\n",
       "[11066 rows x 1 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "53af1d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_list = list(test['headline']) #creating list of 'headline' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5146a100",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = [] #creating empty list to append predicted result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "64a025c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to predict the 'is_sarcastic' that respective 'headline' may fall into\n",
    "for i in test_list:\n",
    "    headline=i\n",
    "    pred = model_logreg.predict([repr(headline)])\n",
    "    prediction.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "48e2bd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction= pd.DataFrame(prediction) #converting list into dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6d1aeea3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11061</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11062</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11063</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11064</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11065</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11066 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0\n",
       "0      1\n",
       "1      1\n",
       "2      1\n",
       "3      0\n",
       "4      0\n",
       "...   ..\n",
       "11061  0\n",
       "11062  1\n",
       "11063  1\n",
       "11064  0\n",
       "11065  0\n",
       "\n",
       "[11066 rows x 1 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction #prediction dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "479886ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction.columns=[\"prediction\"] #renaming column 0 to \"prediction\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "29816b66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11061</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11062</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11063</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11064</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11065</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11066 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       prediction\n",
       "0               1\n",
       "1               1\n",
       "2               1\n",
       "3               0\n",
       "4               0\n",
       "...           ...\n",
       "11061           0\n",
       "11062           1\n",
       "11063           1\n",
       "11064           0\n",
       "11065           0\n",
       "\n",
       "[11066 rows x 1 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2608f73e",
   "metadata": {},
   "outputs": [],
   "source": [
    " prediction.to_csv(\"Prediction.csv\", index=False) #converting dataframe into csv file without index"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
